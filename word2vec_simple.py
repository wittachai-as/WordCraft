#!/usr/bin/env python3
"""
Simple Word2Vec Implementation
‡πÉ‡∏ä‡πâ Word2Vec model ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á gensim
"""

import requests
import json
import os
from typing import Optional, List, Tuple

class SimpleWord2Vec:
    def __init__(self):
        self.model_url = "https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip"
        self.model_file = "word2vec_model.vec"
        self.vectors = {}
        self.vocab = set()
        
    def download_model(self):
        """‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Word2Vec model"""
        if os.path.exists(self.model_file):
            print(f"‚úÖ Model ‡πÑ‡∏ü‡∏•‡πå {self.model_file} ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß")
            return True
            
        print("üì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Word2Vec model...")
        print("‚ö†Ô∏è  ‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà (~1GB) ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà...")
        
        try:
            # ‡πÉ‡∏ä‡πâ model ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤
            response = requests.get("https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip", 
                                  stream=True)
            if response.status_code == 200:
                with open(self.model_file, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                print(f"‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {self.model_file}")
                return True
        except Exception as e:
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î model: {e}")
            return False
    
    def load_model(self):
        """‡πÇ‡∏´‡∏•‡∏î Word2Vec model"""
        if not os.path.exists(self.model_file):
            print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö model ‡πÑ‡∏ü‡∏•‡πå")
            return False
            
        print("üìñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î Word2Vec model...")
        try:
            with open(self.model_file, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if i == 0:  # ‡∏Ç‡πâ‡∏≤‡∏° header
                        continue
                    if i > 10000:  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
                        break
                        
                    parts = line.strip().split()
                    if len(parts) > 1:
                        word = parts[0]
                        vector = [float(x) for x in parts[1:]]
                        self.vectors[word] = vector
                        self.vocab.add(word)
            
            print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î model ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {len(self.vectors)} ‡∏Ñ‡∏≥")
            return True
        except Exception as e:
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î model: {e}")
            return False
    
    def get_vector(self, word: str) -> Optional[List[float]]:
        """‡∏î‡∏∂‡∏á vector ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥"""
        return self.vectors.get(word.lower())
    
    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì cosine similarity"""
        if len(vec1) != len(vec2):
            return 0.0
            
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        norm1 = sum(a * a for a in vec1) ** 0.5
        norm2 = sum(b * b for b in vec2) ** 0.5
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
            
        return dot_product / (norm1 * norm2)
    
    def most_similar(self, word: str, topn: int = 10) -> List[Tuple[str, float]]:
        """‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"""
        word_vec = self.get_vector(word)
        if not word_vec:
            return []
        
        similarities = []
        for other_word, other_vec in self.vectors.items():
            if other_word != word:
                sim = self.cosine_similarity(word_vec, other_vec)
                similarities.append((other_word, sim))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:topn]
    
    def combine_words(self, word1: str, word2: str) -> Optional[str]:
        """‡∏£‡∏ß‡∏°‡∏™‡∏≠‡∏á‡∏Ñ‡∏≥‡∏î‡πâ‡∏ß‡∏¢ vector arithmetic"""
        vec1 = self.get_vector(word1)
        vec2 = self.get_vector(word2)
        
        if not vec1 or not vec2:
            return None
        
        # Vector arithmetic: vec1 + vec2
        combined_vec = [a + b for a, b in zip(vec1, vec2)]
        
        # ‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ö combined vector
        best_similarity = 0
        best_word = None
        
        for word, vec in self.vectors.items():
            if word not in [word1.lower(), word2.lower()]:
                sim = self.cosine_similarity(combined_vec, vec)
                if sim > best_similarity:
                    best_similarity = sim
                    best_word = word
        
        if best_similarity > 0.3:  # threshold
            return best_word.capitalize()
        
        return None

def test_word2vec():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö Word2Vec"""
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö Simple Word2Vec")
    
    w2v = SimpleWord2Vec()
    
    # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î model
    if not w2v.download_model():
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î model ‡πÑ‡∏î‡πâ")
        return
    
    # ‡πÇ‡∏´‡∏•‡∏î model
    if not w2v.load_model():
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î model ‡πÑ‡∏î‡πâ")
        return
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥
    test_cases = [
        ("king", "queen"),
        ("man", "woman"),
        ("fire", "water"),
        ("earth", "air"),
        ("light", "dark"),
        ("life", "death"),
        ("love", "hate"),
        ("peace", "war"),
        ("hope", "fear"),
        ("strength", "courage")
    ]
    
    print("\nüß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡∏î‡πâ‡∏ß‡∏¢ Word2Vec:")
    print("=" * 50)
    
    for word1, word2 in test_cases:
        result = w2v.combine_words(word1, word2)
        if result:
            print(f"‚úÖ {word1} + {word2} = {result}")
        else:
            print(f"‚ùå {word1} + {word2} = ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á
    print("\nüîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á:")
    print("=" * 50)
    
    test_words = ["king", "fire", "love", "power", "light"]
    for word in test_words:
        similar = w2v.most_similar(word, 5)
        print(f"\n‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ö '{word}':")
        for sim_word, score in similar:
            print(f"  - {sim_word}: {score:.3f}")

if __name__ == "__main__":
    test_word2vec()
